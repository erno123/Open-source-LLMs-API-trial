{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erno123/Open-source-LLMs-API-trial/blob/main/Mistral%20API%20trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ecd268c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecd268c5",
        "outputId": "1e7394f8-bf84-427a-c3ac-830c9d300868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q mistralai\n",
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "import readline\n",
        "import sys\n",
        "from mistralai.client import MistralClient\n",
        "from mistralai.models.chat_completion import ChatMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5e5e8d6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e5e8d6b",
        "outputId": "af33494e-feba-41ff-bac2-ea3b25e24cbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your API key: ··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "api_key = getpass(\"Enter your API key: \")\n",
        "#api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
        "model = \"mistral-small\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "04148f5e",
      "metadata": {
        "id": "04148f5e"
      },
      "outputs": [],
      "source": [
        "client = MistralClient(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_models_response = client.list_models()\n",
        "print(list_models_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAlBGZSA_vTp",
        "outputId": "c03b2810-0d53-47c5-ec18-0bc6ed0500dc"
      },
      "id": "eAlBGZSA_vTp",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object='list' data=[ModelCard(id='mistral-medium', object='model', created=1706106217, owned_by='mistralai', root=None, parent=None, permission=[ModelPermission(id='modelperm-3849f464c68049f28f94736f315fb925', object='model_permission', created=1706106217, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]), ModelCard(id='mistral-small', object='model', created=1706106217, owned_by='mistralai', root=None, parent=None, permission=[ModelPermission(id='modelperm-60004a015cd94f9c9cc39e97698b87f0', object='model_permission', created=1706106217, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]), ModelCard(id='mistral-tiny', object='model', created=1706106217, owned_by='mistralai', root=None, parent=None, permission=[ModelPermission(id='modelperm-79e13a39220e4d379e53cda589d1898f', object='model_permission', created=1706106217, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]), ModelCard(id='mistral-embed', object='model', created=1706106217, owned_by='mistralai', root=None, parent=None, permission=[ModelPermission(id='modelperm-e5075efe309e4ab6a24ca1d329c1becf', object='model_permission', created=1706106217, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "50f62ae8",
      "metadata": {
        "id": "50f62ae8"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    ChatMessage(role=\"user\", content=\"What is the essence of quantum mechanics?\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dc04b735",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc04b735",
        "outputId": "8afdeb6a-0332-40e3-ff1c-a1f3dfe63f71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The essence of quantum mechanics is a probabilistic approach to describing the behavior of particles\n",
            "at the smallest scales, such as electrons and photons. It includes several key principles:  1. Wave-\n",
            "Particle Duality: Particles can exhibit properties of both waves and particles, depending on how\n",
            "they are observed. 2. Superposition: A quantum system can exist in multiple states or places\n",
            "simultaneously, until it is measured. 3. Quantization: Many properties of particles come in\n",
            "discrete, or \"quantized,\" amounts, not continuous ranges. 4. Uncertainty Principle: It is impossible\n",
            "to simultaneously know the exact position and momentum (speed) of a particle. The more precisely one\n",
            "property is known, the less precisely the other can be known. 5. Entanglement: Two or more particles\n",
            "can become \"entangled\" such that the state of one instantaneously influences the state of the other,\n",
            "no matter how far apart they are.  These principles fundamentally differ from classical physics and\n",
            "have been confirmed by a vast array of experiments. However, they also lead to counter-intuitive\n",
            "scenarios that have been the subject of much debate and interpretation among physicists.\n"
          ]
        }
      ],
      "source": [
        "# No streaming\n",
        "\n",
        "chat_response = client.chat(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        ")\n",
        "\n",
        "import textwrap\n",
        "wrapper = textwrap.TextWrapper(width=100)\n",
        "lines = wrapper.fill(chat_response.choices[0].message.content)\n",
        "print(lines)\n",
        "\n",
        "# print(chat_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With streaming\n",
        "import textwrap\n",
        "wrapper = textwrap.TextWrapper(width=80)\n",
        "\n",
        "line_length = 0\n",
        "for chunk in client.chat_stream(model=model, messages=messages):\n",
        "    if chunk.choices[0].delta.content is not None:\n",
        "            #text[-1] += chunk.choices[0].delta.content\n",
        "            print(chunk.choices[0].delta.content, end=\"\")\n",
        "            line_length += len(chunk.choices[0].delta.content)\n",
        "            if line_length > 100:\n",
        "              print(\"\")\n",
        "              line_length = 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YK2GS2wuiEA",
        "outputId": "9761e809-fbe5-4812-b616-f5c0b7d22cb9"
      },
      "id": "_YK2GS2wuiEA",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantum mechanics is a fundamental theory in physics that describes the behavior of matter and energy at very small scales, typically at the level of\n",
            " atoms and subatomic particles. Here are some of the key principles that capture the essence of quantum mechanics:\n",
            "\n",
            "\n",
            "1. Wave-Particle Duality: Quantum particles can exhibit properties of both particles and waves. For example, light can behave\n",
            " as both a wave (exhibiting interference and diffraction) and as a particle ( photons).\n",
            "\n",
            "2. Superposition: Quantum systems can\n",
            " exist in multiple states or configurations simultaneously. This is often described as a particle being in multiple places at the\n",
            " same time. The actual state of the system is not determined until it is measured.\n",
            "\n",
            "3. Uncertainty Principle: Formulated\n",
            " by Werner Heisenberg, the uncertainty principle states that it is impossible to simultaneously know the exact position\n",
            " and momentum (or any pair of complementary properties) of a quantum particle. The more precisely one property\n",
            " is known, the less precisely the other can be known.\n",
            "\n",
            "4. Quantization: Many properties in the quantum world come in discrete, indivisible\n",
            " units, or \"quanta.\" For example, the energy levels of an electron in an atom are quantized, meaning they can only take on specific values\n",
            ".\n",
            "\n",
            "5. Entanglement: Quantum particles can become entangled, meaning their states are instantaneously correlated no matter how far apart\n",
            " they are. This phenomenon, which Albert Einstein famously called \"spooky action at a distance,\" has been experimentally confirmed and forms the basis for technologies\n",
            " like quantum computing and quantum cryptography.\n",
            "\n",
            "6. Wave Function: The state of a quantum system is described by a wave function, a mathematical\n",
            " object that encapsulates all the information about the system. When a measurement is performed, the wave function\n",
            " collapses to a specific outcome, with the probability of each outcome given by the square of the amplitude\n",
            " of the wave function for that outcome.\n",
            "\n",
            "These principles, while counterintuitive, have been extensively verified through experiments and are central to our\n",
            " understanding of the quantum world. Quantum mechanics has been incredibly successful in explaining the behavior of matter and energy\n",
            " at small scales and has numerous applications in modern technology, including lasers, semiconductors,\n",
            " and magnetic resonance imaging (MRI)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_LIST = [\n",
        "    \"mistral-tiny\",\n",
        "    \"mistral-small\",\n",
        "    \"mistral-medium\",\n",
        "]\n",
        "API_KEY = api_key\n",
        "DEFAULT_MODEL = \"mistral-small\"\n",
        "DEFAULT_TEMPERATURE = 0.7\n",
        "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
        "# A dictionary of all commands and their arguments, used for tab completion.\n",
        "COMMAND_LIST = {\n",
        "    \"/new\": {},\n",
        "    \"/help\": {},\n",
        "    \"/model\": {model: {} for model in MODEL_LIST},  # Nested completions for models\n",
        "    \"/system\": {},\n",
        "    \"/temperature\": {},\n",
        "    \"/config\": {},\n",
        "    \"/quit\": {},\n",
        "    \"/exit\": {},\n",
        "}\n",
        "\n",
        "SYSTEM_MESSAGE = \"You are a helpful assistant.\"\n",
        "\n",
        "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
        "\n",
        "logger = logging.getLogger(\"chatbot\")\n",
        "\n",
        "\n",
        "def find_completions(command_dict, parts):\n",
        "    if not parts:\n",
        "        return command_dict.keys()\n",
        "    if parts[0] in command_dict:\n",
        "        return find_completions(command_dict[parts[0]], parts[1:])\n",
        "    else:\n",
        "        return [cmd for cmd in command_dict if cmd.startswith(parts[0])]\n",
        "\n",
        "\n",
        "def completer(text, state):\n",
        "    buffer = readline.get_line_buffer()\n",
        "    line_parts = buffer.lstrip().split(\" \")\n",
        "    options = find_completions(COMMAND_LIST, line_parts[:-1])\n",
        "\n",
        "    try:\n",
        "        return [option for option in options if option.startswith(line_parts[-1])][state]\n",
        "    except IndexError:\n",
        "        return None\n",
        "\n",
        "\n",
        "readline.set_completer(completer)\n",
        "readline.set_completer_delims(\" \")\n",
        "# Enable tab completion\n",
        "readline.parse_and_bind(\"tab: complete\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kayQydfg_pAw"
      },
      "id": "kayQydfg_pAw",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ig-fOZWABXM5"
      },
      "id": "ig-fOZWABXM5",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatBot:\n",
        "    def __init__(\n",
        "        self, api_key, model, system_message=None, temperature=DEFAULT_TEMPERATURE\n",
        "    ):\n",
        "        if not api_key:\n",
        "            raise ValueError(\"An API key must be provided to use the Mistral API.\")\n",
        "        self.client = MistralClient(api_key=api_key)\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "        self.system_message = system_message\n",
        "\n",
        "    def opening_instructions(self):\n",
        "        print(\n",
        "            \"\"\"\n",
        "To chat: type your message and hit enter\n",
        "To start a new chat: /new\n",
        "To switch model: /model <model name>\n",
        "To switch system message: /system <message>\n",
        "To switch temperature: /temperature <temperature>\n",
        "To see current config: /config\n",
        "To exit: /exit, /quit, or hit CTRL+C\n",
        "To see this help: /help\n",
        "\"\"\"\n",
        "        )\n",
        "\n",
        "    def new_chat(self):\n",
        "        print(\"\")\n",
        "        print(\n",
        "            f\"Starting new chat with model: {self.model}, temperature: {self.temperature}\"\n",
        "        )\n",
        "        print(\"\")\n",
        "        self.messages = []\n",
        "        if self.system_message:\n",
        "            self.messages.append(\n",
        "                ChatMessage(role=\"system\", content=self.system_message)\n",
        "            )\n",
        "\n",
        "    def switch_model(self, input):\n",
        "        model = self.get_arguments(input)\n",
        "        if model in MODEL_LIST:\n",
        "            self.model = model\n",
        "            logger.info(f\"Switching model: {model}\")\n",
        "        else:\n",
        "            logger.error(f\"Invalid model name: {model}\")\n",
        "\n",
        "    def switch_system_message(self, input):\n",
        "        system_message = self.get_arguments(input)\n",
        "        if system_message:\n",
        "            self.system_message = system_message\n",
        "            logger.info(f\"Switching system message: {system_message}\")\n",
        "            self.new_chat()\n",
        "        else:\n",
        "            logger.error(f\"Invalid system message: {system_message}\")\n",
        "\n",
        "    def switch_temperature(self, input):\n",
        "        temperature = self.get_arguments(input)\n",
        "        try:\n",
        "            temperature = float(temperature)\n",
        "            if temperature < 0 or temperature > 1:\n",
        "                raise ValueError\n",
        "            self.temperature = temperature\n",
        "            logger.info(f\"Switching temperature: {temperature}\")\n",
        "        except ValueError:\n",
        "            logger.error(f\"Invalid temperature: {temperature}\")\n",
        "\n",
        "    def show_config(self):\n",
        "        print(\"\")\n",
        "        print(f\"Current model: {self.model}\")\n",
        "        print(f\"Current temperature: {self.temperature}\")\n",
        "        print(f\"Current system message: {self.system_message}\")\n",
        "        print(\"\")\n",
        "\n",
        "    def collect_user_input(self):\n",
        "        print(\"\")\n",
        "        return input(\"YOU: \")\n",
        "\n",
        "    def run_inference(self, content):\n",
        "        print(\"\")\n",
        "        print(\"MISTRAL:\")\n",
        "        print(\"\")\n",
        "\n",
        "        self.messages.append(ChatMessage(role=\"user\", content=content))\n",
        "\n",
        "        assistant_response = \"\"\n",
        "        logger.debug(\n",
        "            f\"Running inference with model: {self.model}, temperature: {self.temperature}\"\n",
        "        )\n",
        "        logger.debug(f\"Sending messages: {self.messages}\")\n",
        "        for chunk in self.client.chat_stream(\n",
        "            model=self.model, temperature=self.temperature, messages=self.messages\n",
        "        ):\n",
        "            response = chunk.choices[0].delta.content\n",
        "            if response is not None:\n",
        "                print(response, end=\"\", flush=True)\n",
        "                assistant_response += response\n",
        "\n",
        "        print(\"\", flush=True)\n",
        "\n",
        "        if assistant_response:\n",
        "            self.messages.append(\n",
        "                ChatMessage(role=\"assistant\", content=assistant_response)\n",
        "            )\n",
        "        logger.debug(f\"Current messages: {self.messages}\")\n",
        "\n",
        "    def get_command(self, input):\n",
        "        return input.split()[0].strip()\n",
        "\n",
        "    def get_arguments(self, input):\n",
        "        try:\n",
        "            return \" \".join(input.split()[1:])\n",
        "        except IndexError:\n",
        "            return \"\"\n",
        "\n",
        "    def is_command(self, input):\n",
        "        return self.get_command(input) in COMMAND_LIST\n",
        "\n",
        "    def execute_command(self, input):\n",
        "        command = self.get_command(input)\n",
        "        if command in [\"/exit\", \"/quit\"]:\n",
        "            self.exit()\n",
        "        elif command == \"/help\":\n",
        "            self.opening_instructions()\n",
        "        elif command == \"/new\":\n",
        "            self.new_chat()\n",
        "        elif command == \"/model\":\n",
        "            self.switch_model(input)\n",
        "        elif command == \"/system\":\n",
        "            self.switch_system_message(input)\n",
        "        elif command == \"/temperature\":\n",
        "            self.switch_temperature(input)\n",
        "        elif command == \"/config\":\n",
        "            self.show_config()\n",
        "\n",
        "    def start(self):\n",
        "        self.opening_instructions()\n",
        "        self.new_chat()\n",
        "        while True:\n",
        "            try:\n",
        "                input = self.collect_user_input()\n",
        "                if self.is_command(input):\n",
        "                    self.execute_command(input)\n",
        "                else:\n",
        "                    self.run_inference(input)\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                self.exit()\n",
        "\n",
        "    def exit(self):\n",
        "        logger.debug(\"Exiting chatbot\")\n",
        "        sys.exit(0)"
      ],
      "metadata": {
        "id": "MrjTztqQBXBH"
      },
      "id": "MrjTztqQBXBH",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"A simple chatbot using the Mistral API\"\n",
        "    )\n",
        "\n",
        "    #default=os.environ.get(\"MISTRAL_API_KEY\"),\n",
        "    parser.add_argument(\n",
        "        \"--api-key\",\n",
        "        default = API_KEY,\n",
        "        help=\"Mistral API key. Defaults to environment variable MISTRAL_API_KEY\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-m\",\n",
        "        \"--model\",\n",
        "        choices=MODEL_LIST,\n",
        "        default=DEFAULT_MODEL,\n",
        "        help=\"Model for chat inference. Choices are %(choices)s. Defaults to %(default)s\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-s\", \"--system-message\", help=\"Optional system message to prepend.\",\n",
        "        default=SYSTEM_MESSAGE,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-t\",\n",
        "        \"--temperature\",\n",
        "        type=float,\n",
        "        default=DEFAULT_TEMPERATURE,\n",
        "        help=\"Optional temperature for chat inference. Defaults to %(default)s\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-d\", \"--debug\", action=\"store_true\", help=\"Enable debug logging\"\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "tYF9fWG8BWwc"
      },
      "id": "tYF9fWG8BWwc",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    '''\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.debug:\n",
        "        logger.setLevel(logging.DEBUG)\n",
        "    else:\n",
        "        logger.setLevel(logging.INFO)\n",
        "    '''\n",
        "\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    formatter = logging.Formatter(LOG_FORMAT)\n",
        "\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setFormatter(formatter)\n",
        "    logger.addHandler(ch)\n",
        "\n",
        "    logger.debug(\n",
        "        f\"Starting chatbot with model: {DEFAULT_MODEL}, \"\n",
        "        f\"temperature: {DEFAULT_TEMPERATURE}, \"\n",
        "        f\"system message: {SYSTEM_MESSAGE}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "PEa5qCsqCvY8"
      },
      "id": "PEa5qCsqCvY8",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    try:\n",
        "        bot = ChatBot(API_KEY, DEFAULT_MODEL, SYSTEM_MESSAGE, DEFAULT_TEMPERATURE)\n",
        "        bot.start()\n",
        "    except Exception as e:\n",
        "        logger.error(e)\n",
        "        sys.exit(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "AorgfmjmD9Mi",
        "outputId": "58020369-c30f-464d-ef95-bb2c11df9c95"
      },
      "id": "AorgfmjmD9Mi",
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "To chat: type your message and hit enter\n",
            "To start a new chat: /new\n",
            "To switch model: /model <model name>\n",
            "To switch system message: /system <message>\n",
            "To switch temperature: /temperature <temperature>\n",
            "To see current config: /config\n",
            "To exit: /exit, /quit, or hit CTRL+C\n",
            "To see this help: /help\n",
            "\n",
            "\n",
            "Starting new chat with model: mistral-small, temperature: 0.7\n",
            "\n",
            "\n",
            "YOU: /exit\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "0",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}