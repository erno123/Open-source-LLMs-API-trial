{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erno123/Mistral-trial/blob/main/Basic%20Mistral%20API%20trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ecd268c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecd268c5",
        "outputId": "9ef8b6d1-8c71-4f14-943f-3025d571218a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q mistralai\n",
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "import readline\n",
        "import sys\n",
        "from mistralai.client import MistralClient\n",
        "from mistralai.models.chat_completion import ChatMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5e5e8d6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e5e8d6b",
        "outputId": "ce106934-6ae8-4a6b-cd50-0a2085eb461f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your API key: ··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "api_key = getpass(\"Enter your API key: \")\n",
        "#api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
        "model = \"mistral-small\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "04148f5e",
      "metadata": {
        "id": "04148f5e"
      },
      "outputs": [],
      "source": [
        "client = MistralClient(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_models_response = client.list_models()\n",
        "print(list_models_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAlBGZSA_vTp",
        "outputId": "2bd5b1a9-19a2-4697-b819-975e89ca577d"
      },
      "id": "eAlBGZSA_vTp",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object='list' data=[ModelCard(id='mistral-medium', object='model', created=1705580202, owned_by='mistralai', root=None, parent=None, permission=[ModelPermission(id='modelperm-029e5dc9916f4b5cba6ea962743581a5', object='model_permission', created=1705580202, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]), ModelCard(id='mistral-small', object='model', created=1705580202, owned_by='mistralai', root=None, parent=None, permission=[ModelPermission(id='modelperm-d8bb5c84abd64bae93953f150c548bcd', object='model_permission', created=1705580202, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]), ModelCard(id='mistral-tiny', object='model', created=1705580202, owned_by='mistralai', root=None, parent=None, permission=[ModelPermission(id='modelperm-f72e694a825a4b84bf86e31f77c0a4d9', object='model_permission', created=1705580202, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]), ModelCard(id='mistral-embed', object='model', created=1705580202, owned_by='mistralai', root=None, parent=None, permission=[ModelPermission(id='modelperm-4d2412e424eb4e349e4b2aa68e9d5394', object='model_permission', created=1705580202, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "50f62ae8",
      "metadata": {
        "id": "50f62ae8"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    ChatMessage(role=\"user\", content=\"What is the essence of quantum mechanics?\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dc04b735",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc04b735",
        "outputId": "7acef0d3-fb75-4d00-e0e2-0277cc147635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantum mechanics is a fundamental theory in physics that describes the behavior of matter and\n",
            "energy at very small scales, typically at the level of atoms and subatomic particles. Here are some\n",
            "of the key principles that capture the essence of quantum mechanics:  1. Wave-Particle Duality:\n",
            "Quantum particles can exhibit both wave-like and particle-like properties. For example, light can\n",
            "behave as both a wave and a particle (photon), and electrons can behave as both particles and waves.\n",
            "2. Superposition: Quantum systems can exist in multiple states simultaneously, a phenomenon known as\n",
            "superposition. This means that a quantum particle can be in several places at the same time, or have\n",
            "multiple values of energy or spin, until it is measured. 3. Uncertainty Principle: Formulated by\n",
            "Werner Heisenberg, the uncertainty principle states that it is impossible to simultaneously measure\n",
            "the exact position and momentum (or any pair of complementary properties) of a quantum particle. The\n",
            "more precisely one property is measured, the less precisely the other can be known. 4. Quantization:\n",
            "Many properties in the quantum world, such as energy and angular momentum, come in discrete,\n",
            "indivisible units, unlike continuous quantities in the classical world. This is why these properties\n",
            "are said to be \"quantized.\" 5. Entanglement: Quantum particles can become entangled, meaning their\n",
            "properties become correlated in such a way that the state of one particle instantly influences the\n",
            "state of the other, regardless of the distance between them. This phenomenon, which Albert Einstein\n",
            "famously called \"spooky action at a distance,\" is a direct consequence of quantum mechanics and has\n",
            "been experimentally confirmed. 6. Collapse of the Wave Function: When a quantum system is measured,\n",
            "its superposition collapses to a single definite state. This is sometimes referred to as the\n",
            "\"observer effect,\" as the act of measurement seems to play a special role in determining the\n",
            "outcome.  These principles, while counterintuitive, have been extensively tested and verified\n",
            "through numerous experiments. Quantum mechanics is not only a cornerstone of modern physics but also\n",
            "underpins technologies like lasers, semiconductors, and quantum computing.\n"
          ]
        }
      ],
      "source": [
        "# No streaming\n",
        "\n",
        "chat_response = client.chat(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        ")\n",
        "\n",
        "import textwrap\n",
        "wrapper = textwrap.TextWrapper(width=100)\n",
        "lines = wrapper.fill(chat_response.choices[0].message.content)\n",
        "print(lines)\n",
        "\n",
        "# print(chat_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With streaming\n",
        "import textwrap\n",
        "wrapper = textwrap.TextWrapper(width=80)\n",
        "\n",
        "line_length = 0\n",
        "for chunk in client.chat_stream(model=model, messages=messages):\n",
        "    if chunk.choices[0].delta.content is not None:\n",
        "            #text[-1] += chunk.choices[0].delta.content\n",
        "            print(chunk.choices[0].delta.content, end=\"\")\n",
        "            line_length += len(chunk.choices[0].delta.content)\n",
        "            if line_length > 100:\n",
        "              print(\"\")\n",
        "              line_length = 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YK2GS2wuiEA",
        "outputId": "c01ccc7c-a293-4bd4-b82d-82b44bc51d9e"
      },
      "id": "_YK2GS2wuiEA",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The essence of quantum mechanics is a fundamentally new way of describing and predicting the behavior of matter and energy at very small scales,\n",
            " such as molecules, atoms, and subatomic particles like electrons and photons. Here are some key principles:\n",
            "\n",
            "1. **Wave\n",
            "-Particle Duality**: Quantum objects can exhibit characteristics of both particles and waves. For example\n",
            ", light can behave as both a wave (exhibiting interference and diffraction patterns) and a particle (as photons in the photoelectric effect\n",
            ").\n",
            "\n",
            "2. **Superposition**: A quantum system can exist in multiple states or places at the same time, each with a certain probability. This\n",
            " is famously illustrated by Schrödinger's cat thought experiment.\n",
            "\n",
            "3. **Quantization**: Many physical quantities come in discrete\n",
            ", \"quantized\" amounts, rather than continuous ranges. For example, the energy levels of an electron in an atom are quantized.\n",
            "\n",
            "4\n",
            ". **Entanglement**: Two or more quantum particles can become \"entangled\" such that the state of one instantaneously affects the state of the\n",
            " other, no matter how far apart they are.\n",
            "\n",
            "5. **Uncertainty Principle**: Formulated by Werner Heisenberg\n",
            ", it states that it is impossible to simultaneously know the exact position and momentum (or any pair of\n",
            " complementary properties) of a quantum particle.\n",
            "\n",
            "6. **Probabilistic Interpretation**: The description of a quantum system is prob\n",
            "abilistic, not deterministic. We can only predict the probabilities of different outcomes, not the exact\n",
            " outcome of a measurement.\n",
            "\n",
            "These principles fundamentally change our understanding of the nature of reality and\n",
            " the way we do physics. However, they also lead to many counterintuitive results and paradoxes, which have been a subject of debate and\n",
            " exploration in the field of quantum mechanics."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_LIST = [\n",
        "    \"mistral-tiny\",\n",
        "    \"mistral-small\",\n",
        "    \"mistral-medium\",\n",
        "]\n",
        "API_KEY = api_key\n",
        "DEFAULT_MODEL = \"mistral-small\"\n",
        "DEFAULT_TEMPERATURE = 0.7\n",
        "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
        "# A dictionary of all commands and their arguments, used for tab completion.\n",
        "COMMAND_LIST = {\n",
        "    \"/new\": {},\n",
        "    \"/help\": {},\n",
        "    \"/model\": {model: {} for model in MODEL_LIST},  # Nested completions for models\n",
        "    \"/system\": {},\n",
        "    \"/temperature\": {},\n",
        "    \"/config\": {},\n",
        "    \"/quit\": {},\n",
        "    \"/exit\": {},\n",
        "}\n",
        "\n",
        "SYSTEM_MESSAGE = \"You are a helpful assistant.\"\n",
        "\n",
        "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
        "\n",
        "logger = logging.getLogger(\"chatbot\")\n",
        "\n",
        "\n",
        "def find_completions(command_dict, parts):\n",
        "    if not parts:\n",
        "        return command_dict.keys()\n",
        "    if parts[0] in command_dict:\n",
        "        return find_completions(command_dict[parts[0]], parts[1:])\n",
        "    else:\n",
        "        return [cmd for cmd in command_dict if cmd.startswith(parts[0])]\n",
        "\n",
        "\n",
        "def completer(text, state):\n",
        "    buffer = readline.get_line_buffer()\n",
        "    line_parts = buffer.lstrip().split(\" \")\n",
        "    options = find_completions(COMMAND_LIST, line_parts[:-1])\n",
        "\n",
        "    try:\n",
        "        return [option for option in options if option.startswith(line_parts[-1])][state]\n",
        "    except IndexError:\n",
        "        return None\n",
        "\n",
        "\n",
        "readline.set_completer(completer)\n",
        "readline.set_completer_delims(\" \")\n",
        "# Enable tab completion\n",
        "readline.parse_and_bind(\"tab: complete\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kayQydfg_pAw"
      },
      "id": "kayQydfg_pAw",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ig-fOZWABXM5"
      },
      "id": "ig-fOZWABXM5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatBot:\n",
        "    def __init__(\n",
        "        self, api_key, model, system_message=None, temperature=DEFAULT_TEMPERATURE\n",
        "    ):\n",
        "        if not api_key:\n",
        "            raise ValueError(\"An API key must be provided to use the Mistral API.\")\n",
        "        self.client = MistralClient(api_key=api_key)\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "        self.system_message = system_message\n",
        "\n",
        "    def opening_instructions(self):\n",
        "        print(\n",
        "            \"\"\"\n",
        "To chat: type your message and hit enter\n",
        "To start a new chat: /new\n",
        "To switch model: /model <model name>\n",
        "To switch system message: /system <message>\n",
        "To switch temperature: /temperature <temperature>\n",
        "To see current config: /config\n",
        "To exit: /exit, /quit, or hit CTRL+C\n",
        "To see this help: /help\n",
        "\"\"\"\n",
        "        )\n",
        "\n",
        "    def new_chat(self):\n",
        "        print(\"\")\n",
        "        print(\n",
        "            f\"Starting new chat with model: {self.model}, temperature: {self.temperature}\"\n",
        "        )\n",
        "        print(\"\")\n",
        "        self.messages = []\n",
        "        if self.system_message:\n",
        "            self.messages.append(\n",
        "                ChatMessage(role=\"system\", content=self.system_message)\n",
        "            )\n",
        "\n",
        "    def switch_model(self, input):\n",
        "        model = self.get_arguments(input)\n",
        "        if model in MODEL_LIST:\n",
        "            self.model = model\n",
        "            logger.info(f\"Switching model: {model}\")\n",
        "        else:\n",
        "            logger.error(f\"Invalid model name: {model}\")\n",
        "\n",
        "    def switch_system_message(self, input):\n",
        "        system_message = self.get_arguments(input)\n",
        "        if system_message:\n",
        "            self.system_message = system_message\n",
        "            logger.info(f\"Switching system message: {system_message}\")\n",
        "            self.new_chat()\n",
        "        else:\n",
        "            logger.error(f\"Invalid system message: {system_message}\")\n",
        "\n",
        "    def switch_temperature(self, input):\n",
        "        temperature = self.get_arguments(input)\n",
        "        try:\n",
        "            temperature = float(temperature)\n",
        "            if temperature < 0 or temperature > 1:\n",
        "                raise ValueError\n",
        "            self.temperature = temperature\n",
        "            logger.info(f\"Switching temperature: {temperature}\")\n",
        "        except ValueError:\n",
        "            logger.error(f\"Invalid temperature: {temperature}\")\n",
        "\n",
        "    def show_config(self):\n",
        "        print(\"\")\n",
        "        print(f\"Current model: {self.model}\")\n",
        "        print(f\"Current temperature: {self.temperature}\")\n",
        "        print(f\"Current system message: {self.system_message}\")\n",
        "        print(\"\")\n",
        "\n",
        "    def collect_user_input(self):\n",
        "        print(\"\")\n",
        "        return input(\"YOU: \")\n",
        "\n",
        "    def run_inference(self, content):\n",
        "        print(\"\")\n",
        "        print(\"MISTRAL:\")\n",
        "        print(\"\")\n",
        "\n",
        "        self.messages.append(ChatMessage(role=\"user\", content=content))\n",
        "\n",
        "        assistant_response = \"\"\n",
        "        logger.debug(\n",
        "            f\"Running inference with model: {self.model}, temperature: {self.temperature}\"\n",
        "        )\n",
        "        logger.debug(f\"Sending messages: {self.messages}\")\n",
        "        for chunk in self.client.chat_stream(\n",
        "            model=self.model, temperature=self.temperature, messages=self.messages\n",
        "        ):\n",
        "            response = chunk.choices[0].delta.content\n",
        "            if response is not None:\n",
        "                print(response, end=\"\", flush=True)\n",
        "                assistant_response += response\n",
        "\n",
        "        print(\"\", flush=True)\n",
        "\n",
        "        if assistant_response:\n",
        "            self.messages.append(\n",
        "                ChatMessage(role=\"assistant\", content=assistant_response)\n",
        "            )\n",
        "        logger.debug(f\"Current messages: {self.messages}\")\n",
        "\n",
        "    def get_command(self, input):\n",
        "        return input.split()[0].strip()\n",
        "\n",
        "    def get_arguments(self, input):\n",
        "        try:\n",
        "            return \" \".join(input.split()[1:])\n",
        "        except IndexError:\n",
        "            return \"\"\n",
        "\n",
        "    def is_command(self, input):\n",
        "        return self.get_command(input) in COMMAND_LIST\n",
        "\n",
        "    def execute_command(self, input):\n",
        "        command = self.get_command(input)\n",
        "        if command in [\"/exit\", \"/quit\"]:\n",
        "            self.exit()\n",
        "        elif command == \"/help\":\n",
        "            self.opening_instructions()\n",
        "        elif command == \"/new\":\n",
        "            self.new_chat()\n",
        "        elif command == \"/model\":\n",
        "            self.switch_model(input)\n",
        "        elif command == \"/system\":\n",
        "            self.switch_system_message(input)\n",
        "        elif command == \"/temperature\":\n",
        "            self.switch_temperature(input)\n",
        "        elif command == \"/config\":\n",
        "            self.show_config()\n",
        "\n",
        "    def start(self):\n",
        "        self.opening_instructions()\n",
        "        self.new_chat()\n",
        "        while True:\n",
        "            try:\n",
        "                input = self.collect_user_input()\n",
        "                if self.is_command(input):\n",
        "                    self.execute_command(input)\n",
        "                else:\n",
        "                    self.run_inference(input)\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                self.exit()\n",
        "\n",
        "    def exit(self):\n",
        "        logger.debug(\"Exiting chatbot\")\n",
        "        sys.exit(0)"
      ],
      "metadata": {
        "id": "MrjTztqQBXBH"
      },
      "id": "MrjTztqQBXBH",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"A simple chatbot using the Mistral API\"\n",
        "    )\n",
        "\n",
        "    #default=os.environ.get(\"MISTRAL_API_KEY\"),\n",
        "    parser.add_argument(\n",
        "        \"--api-key\",\n",
        "        default = API_KEY,\n",
        "        help=\"Mistral API key. Defaults to environment variable MISTRAL_API_KEY\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-m\",\n",
        "        \"--model\",\n",
        "        choices=MODEL_LIST,\n",
        "        default=DEFAULT_MODEL,\n",
        "        help=\"Model for chat inference. Choices are %(choices)s. Defaults to %(default)s\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-s\", \"--system-message\", help=\"Optional system message to prepend.\",\n",
        "        default=SYSTEM_MESSAGE,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-t\",\n",
        "        \"--temperature\",\n",
        "        type=float,\n",
        "        default=DEFAULT_TEMPERATURE,\n",
        "        help=\"Optional temperature for chat inference. Defaults to %(default)s\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-d\", \"--debug\", action=\"store_true\", help=\"Enable debug logging\"\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "tYF9fWG8BWwc"
      },
      "id": "tYF9fWG8BWwc",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    '''\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.debug:\n",
        "        logger.setLevel(logging.DEBUG)\n",
        "    else:\n",
        "        logger.setLevel(logging.INFO)\n",
        "    '''\n",
        "\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    formatter = logging.Formatter(LOG_FORMAT)\n",
        "\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setFormatter(formatter)\n",
        "    logger.addHandler(ch)\n",
        "\n",
        "    logger.debug(\n",
        "        f\"Starting chatbot with model: {DEFAULT_MODEL}, \"\n",
        "        f\"temperature: {DEFAULT_TEMPERATURE}, \"\n",
        "        f\"system message: {SYSTEM_MESSAGE}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "PEa5qCsqCvY8"
      },
      "id": "PEa5qCsqCvY8",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    try:\n",
        "        bot = ChatBot(API_KEY, DEFAULT_MODEL, SYSTEM_MESSAGE, DEFAULT_TEMPERATURE)\n",
        "        bot.start()\n",
        "    except Exception as e:\n",
        "        logger.error(e)\n",
        "        sys.exit(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AorgfmjmD9Mi",
        "outputId": "a13943f5-d04d-4bed-9c3d-03093053ac0f"
      },
      "id": "AorgfmjmD9Mi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "To chat: type your message and hit enter\n",
            "To start a new chat: /new\n",
            "To switch model: /model <model name>\n",
            "To switch system message: /system <message>\n",
            "To switch temperature: /temperature <temperature>\n",
            "To see current config: /config\n",
            "To exit: /exit, /quit, or hit CTRL+C\n",
            "To see this help: /help\n",
            "\n",
            "\n",
            "Starting new chat with model: mistral-small, temperature: 0.7\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
